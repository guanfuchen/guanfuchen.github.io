<!DOCTYPE html>
<html class="no-js" lang="en-US" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#">
<head>
    <meta charset="utf-8">

    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="description" content="">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">


<meta name="keywords" content="">

 
<meta property="og:type" content="article"/>
<meta property="og:description" content=""/>
<meta property="og:title" content="计算机视觉常用数据集 : spf13.com"/>
<meta property="og:site_name" content="spf13 is Steve Francia"/>
<meta property="og:image" content="" />
<meta property="og:image:type" content="image/jpeg" />
<meta property="og:image:width" content="" />
<meta property="og:image:height" content="" />
<meta property="og:url" content="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8F%91%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2017-10-31"/>
<meta property="article:modified_time" content="2017-10-31"/>





<meta name="twitter:card" content="summary">

<meta name="twitter:site" content="@spf13">
<meta name="twitter:title" content="计算机视觉常用数据集 : spf13.com">
<meta name="twitter:creator" content="@spf13">
<meta name="twitter:description" content="">
<meta name="twitter:image:src" content="">
<meta name="twitter:domain" content="spf13.com">



    <base href="https://guanfuchen.github.io">
    <title> 计算机视觉常用数据集 - spf13.com </title>
    <link rel="canonical" href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8F%91%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/">
    

    <link href='https://fonts.lug.ustc.edu.cn/css?family=Fjalla+One|Open+Sans:300' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="https://guanfuchen.github.io/static/css/style.css">

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" href="/apple-touch-icon.png" />
</head>

<body lang="en" itemscope itemtype="http://schema.org/Article">
<header id="header">
    
      
    
    <div align="center">
        <a href="https://guanfuchen.github.io">
        <img src="https://guanfuchen.github.io/media/avatar.png">
        </a>
    </div>
    <div align="center">guanfuchen</div>
    <nav id="nav">
            <ul id="mainnav">
            <li>
                <a href="https://guanfuchen.github.io/post/">
                <span class="icon"> <i aria-hidden="true" class="icon-quill"></i></span>
                <span> 博客 </span>
            </a>
            </li>
            
            
                
                
            
            
            
            
                
                
            
            
            <li>
            <a href="http://github.com/guanfuchen">
                <span class="icon"> <i aria-hidden="true" class="icon-13"></i></span>
                <span> 关于 </span>
            </a>
            </li>
            <li>
                <a href="https://guanfuchen.github.io/resume.pdf">
                    <span class="icon"> <i aria-hidden="true" class="icon-console"></i></span>
                    <span> 简历 </span>
                </a>
            </li>
        </ul>

    
    </nav>
</header>



<section id="main">
  <h1 itemprop="name" id="title">计算机视觉常用数据集</h1>
  <div>
        <article itemprop="articleBody" id="content">
           

<hr />

<h1 id="概述">概述</h1>

<p>本仓库主要收集计算机视觉相关领域的常用数据集。
- <a href="http://www.cvpapers.com/datasets.html">CV Datasets on the web</a> cvpapers提供的分类好的常用计算机视觉数据集网站，包括detection，classification，recognition等等。
- <a href="https://github.com/AIBluefisher/ComputerVisionDatasets">ComputerVisionDatasets</a> 作者提供的常用数据集；</p>

<hr />

<h1 id="视频预测数据集">视频预测数据集</h1>

<p><a href="https://github.com/yoosan/video-understanding-dataset">video-understanding-dataset</a> 视频理解数据集收集，可以参考部分</p>

<h2 id="moving-mnist">Moving MNIST</h2>

<p><a href="http://www.cs.toronto.edu/~nitish/unsupervised_video/">Moving MNIST</a></p>

<p>Moving MNIST包含了10000序列，每一个序列在64x64帧中包含了20个长度显示2个数字运动。</p>

<p><img src="http://www.cs.toronto.edu/~nitish/unsupervised_video/images/000000.gif" alt="" /> <img src="http://www.cs.toronto.edu/~nitish/unsupervised_video/images/000001.gif" alt="" /></p>

<h2 id="ucf101">UCF101</h2>

<p><a href="http://crcv.ucf.edu/data/UCF101.php">UCF101 - Action Recognition Data Set</a></p>

<h2 id="e-vds">e-VDS</h2>

<p><a href="https://engineering.purdue.edu/elab/eVDS/">e-VDS</a></p>

<p><img src="http://chenguanfuqq.oschina.io/tuquan/img_2017_11/2017_11_16_12_56_53.png" alt="" /></p>

<h2 id="twenbn数据集">TwenBN数据集</h2>

<p><a href="https://www.jiqizhixin.com/articles/2017-06-27-5">TwenBN发布两个大型DL视频数据集：助力机器视觉通用智能</a> 其中提供了手势识别和物体移动的两个数据集</p>

<p><a href="https://www.twentybn.com/datasets/jester">THE 20BN-JESTER DATASET</a> 手势识别数据集</p>

<p><a href="https://www.twentybn.com/datasets/something-something">THE 20BN-SOMETHING-SOMETHING DATASET</a> 人和物交互视频数据集</p>

<p><a href="https://github.com/TwentyBN/twentybn-dl">twentybn-dl</a> 数据集下载脚本</p>

<p><img src="http://chenguanfuqq.oschina.io/tuquan/img_2017_11/2017_11_27_11_30_23.png" alt="" /></p>

<h2 id="push-dataset">Push Dataset</h2>

<p>机械臂操作视频</p>

<p><a href="https://sites.google.com/site/brainrobotdata/home/push-dataset">Push Dataset</a></p>

<h2 id="davis">DAVIS</h2>

<p><a href="https://github.com/fperazzi/davis-2017">davis-2017</a></p>

<p><a href="http://davischallenge.org/challenge2017/index.html">DAVIS Challenge on Video Object Segmentation 2017</a></p>

<p><img src="http://davischallenge.org/images/teaser/2017/scooter-board.jpg" alt="" /></p>

<p><img src="http://davischallenge.org/images/teaser/2017/boxing-fisheye.jpg" alt="" /></p>

<hr />

<h1 id="语义分割数据集">语义分割数据集</h1>

<p><a href="http://blog.csdn.net/u010069760/article/details/77847595">Datasets for ADAS</a></p>

<p><a href="http://dongzhuoyao.com/image-segmentation-dataset/">语义分割常用数据集</a></p>

<p><a href="https://zhuanlan.zhihu.com/p/25138563">各领域公开数据集下载</a></p>

<hr />

<h1 id="语义分割数据代码">语义分割数据代码</h1>

<p><a href="https://github.com/fvisin/dataset_loaders">dataset_loaders</a> fvision提供的常用的语义和视频数据loader，其中同时提供了数据集的扩充方法。</p>

<hr />

<h1 id="合成数据集">合成数据集</h1>

<h2 id="相关论文">相关论文</h2>

<ul>
<li>UnrealCV: Connecting Computer Vision to Unreal Engine <a href="https://arxiv.org/abs/1609.01326">论文</a> <a href="https://github.com/unrealcv/synthetic-computer-vision">代码</a> <a href="http://unrealcv.org/">项目主页</a> 这个提供了常用的合成数据集的相关论文</li>
<li>Playing for Data: Ground Truth from Computer Games <a href="https://arxiv.org/abs/1608.02192">论文</a> <a href="https://bitbucket.org/visinf/projects-2016-playing-for-data">代码</a> <a href="https://download.visinf.tu-darmstadt.de/data/from_games/index.html">项目主页</a></li>
</ul>

<hr />

<h1 id="lsun">LSUN</h1>

<p><img src="http://lsun.cs.princeton.edu/img/boston_half.jpg" alt="" /></p>

<p>大尺度场景理解挑战，该挑战从2015年开始，直至现在，PASCAL VOC和ImageNet ILSVRC的挑战在过去十年中已经使对象识别取得了显着进步。我们计划借这个机制，加快场景理解的进度。与ICCV / ECCV每年举办的以物象为中心的ImageNet ILSVRC挑战赛相辅相成，我们每年都会在CVPR主办一个以场景为中心的挑战。我们的挑战主要集中在现场理解中的四个主要任务，包括场景分类，显着预测，房间布局估计和字幕生成（由MS COCO主办）。受到最近使用大数据（如深度学习）的成功启发，我们将重点提供比现有数据大至少几倍的基准，以支持培训这些数据饥饿算法。通过以年度挑战格式提供一套大型基准测试，我们预计未来几年将会为现场认识取得重大进展。</p>

<p><a href="http://lsun.cs.princeton.edu">Large-scale Scene Understanding Challenge</a></p>

<h2 id="lsun2015">LSUN2015</h2>

<p><a href="http://lsun.cs.princeton.edu/2015/">LSUN2015</a></p>

<p><img src="http://chenguanfuqq.oschina.io/tuquan/img_2017_10/2017_10_31_14_31_7.png" alt="" /></p>

<h2 id="lsun2016">LSUN2016</h2>

<p><a href="http://lsun.cs.princeton.edu/2016/">LSUN2016</a></p>

<h2 id="lsun2017">LSUN2017</h2>

<p><a href="http://lsun.cs.princeton.edu/2017/">LSUN2017</a></p>

<hr />

<h1 id="cityscapes">cityscapes</h1>

<p>该数据集包含了5000张高质量标注的图像，20000张粗略标注的图像，同时覆盖了50个不同的城市。总共有30类语义，实例，稠密像素标注。同时还包括附加的元数据，比如前后视频帧、双目、GPS和车辆里程计。</p>

<p><a href="https://arxiv.org/abs/1604.01685">The Cityscapes Dataset for Semantic Urban Scene Understanding</a></p>

<p><a href="https://github.com/mcordts/cityscapesScripts">cityscapesScripts</a></p>

<p><a href="https://www.cityscapes-dataset.com/benchmarks/">cityscapes数据集</a></p>

<hr />

<h1 id="camvid数据集">CamVid数据集</h1>

<p><a href="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/">Motion-based Segmentation and Recognition Dataset</a></p>

<p>数据集示例
<img src="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/pr/DBOverview1_1_huff_0000964.jpg" alt="" /></p>

<p>标签分布情况
<img src="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/pr/DataPercents.jpg" alt="" /></p>

<hr />

<h1 id="mapillary-vistas数据集">Mapillary Vistas数据集</h1>

<p>近日Mapillary发布了Mapillary Vistas数据集 - 世界上最大和最多样化的公众可用的像素精确和实例特定的街道级图像数据集，以帮助全球范围内的无人驾驶和自主运输技术。网页链接 数据集和相应的研究论文等：网页链接
1）25,000个高分辨率图像（分为18,000个用于训练，2,000个验证，5,000个测试;平均分辨率约为900万像素），具有从200万个手动绘制的多边形的像素点注释
2）100个对象类别，其中60个实例特定（即枚举对象）
3）涵盖北美和南美，欧洲，非洲，亚洲和大洋洲的全球地理覆盖
4）天气条件（太阳，雨，雪，雾，阴霾）和捕获时间（黎明，白天，黄昏甚至夜晚）的高度变异性
5）相机传感器范围广泛，焦距变化，图像宽高比以及不同类型的相机噪音
6）不同的拍摄观点（从道路，人行道和越野）</p>

<p><a href="https://www.mapillary.com/">Street-level imagery for the future of maps</a></p>

<p><a href="http://www.ppvke.com/Answer/question/26782">【Mapillary Vistas数据集】像素精确和实例特定的街道级图像数据集</a></p>

<p>The Mapillary Vistas Dataset for Semantic Understanding of Street Scenes</p>

<hr />

<h1 id="bdd-data数据集">bdd-data数据集</h1>

<p><a href="https://github.com/ucbdrive/bdd-data">bdd-data</a> 包含了目标检测和语义分割数据集，对应主页<a href="http://bdd-data.berkeley.edu/">http://bdd-data.berkeley.edu/</a>，论文BDD100K: A Diverse Driving Video Database with Scalable Annotation Tooling。</p>

<hr />

<h1 id="分类数据集">分类数据集</h1>

<hr />

<h2 id="102-category-flower-dataset">102 Category Flower Dataset</h2>

<p>Automated flower classification over a large number of classes</p>

<p><a href="http://www.robots.ox.ac.uk/~vgg/data/flowers/102/">102 Category Flower Dataset</a></p>

<p><img src="http://chenguanfuqq.gitee.io/tuquan2/img_2018_5/Screen_Shot_2018-06-07_17.21.53.png" alt="" /></p>

<hr />

<h1 id="cifar-10">CIFAR-10</h1>

<ul>
<li><a href="https://arxiv.org/abs/1806.00451">Do CIFAR-10 Classifiers Generalize to CIFAR-10?</a> 最新的数据集。</li>
</ul>

<hr />

<h1 id="目标检测数据集">目标检测数据集</h1>

<hr />

<h2 id="pets-2009-benchmark-data">PETS 2009 Benchmark Data</h2>

<p>该数据集包含了不同人群活动的多传感器数据。</p>

<p><a href="http://www.cvg.reading.ac.uk/PETS2009/a.html">PETS 2009 Benchmark Data</a></p>

        </article>
  </div>
</section>



<aside id="meta">

    <div>
        <section id="datecount">
          <h4 id="date"> Tue Oct 31, 2017 </h4>
          <h5 id="wc"> 300 Words </h5>
          <h5 id="readtime"> Read in about 1 Min </h5>
        </section>
        <ul id="categories">
          
        </ul>
        <ul id="tags">
          
        </ul>
    </div>

    <div>
        <section id="prev">
            &nbsp;<a class="previous" href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_10/sklearn%E4%BD%BF%E7%94%A8%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/"><i class="icon-arrow-left"></i> Sklearn使用相关问题</a><br>
        </section>
        <section id="next">
            &nbsp;<a class="next" href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_10/vehicle-detection%E9%A1%B9%E7%9B%AE%E8%A7%A3%E6%9E%90/">Vehicle Detection项目解析 <i class="icon-arrow-right"></i></a>
        </section>
    </div>

    

            
            
            
            
            

            
            
                
            
            
            
            
            
            
            
            
            
            
            
            
                
                
            
            
            
            
            
            
            
            
            


        
    
    
    
                
                
            
                                     
                                     
                                     
                                 
                                 
                                 
                                 
                                 
                                 

        

</aside>

<meta itemprop="wordCount" content="208">
<meta itemprop="datePublished" content="2017-10-31">
<meta itemprop="url" content="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8F%91%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/">


<aside id=comments>
    <div><h2> Comments </h2></div>
    <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "guanfuchen" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</aside>

<footer>
  <div>
    <p>
    &copy; 2017 <span itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">guanfuchen.</span></span>
    Powered by <a href="http://gohugo.io">Hugo</a>.
  </div>
</footer>
<script type="text/javascript">
(function(){var j=function(a,b){return window.getComputedStyle?getComputedStyle(a).getPropertyValue(b):a.currentStyle[b]};var k=function(a,b,c){if(a.addEventListener)a.addEventListener(b,c,false);else a.attachEvent('on'+b,c)};var l=function(a,b){for(key in b)if(b.hasOwnProperty(key))a[key]=b[key];return a};window.fitText=function(d,e,f){var g=l({'minFontSize':-1/0,'maxFontSize':1/0},f);var h=function(a){var b=e||1;var c=function(){a.style.fontSize=Math.max(Math.min(a.clientWidth/(b*10),parseFloat(g.maxFontSize)),parseFloat(g.minFontSize))+'px'};c();k(window,'resize',c)};if(d.length)for(var i=0;i<d.length;i++)h(d[i]);else h(d);return d}})();
fitText(document.getElementById('title'), 1)
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-7131036-1', 'spf13.com');
  ga('require', 'linkid', 'linkid.js');
  ga('require', 'displayfeatures');
  ga('send', 'pageview');
</script>
</body>
</html>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript"
        src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

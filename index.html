<!DOCTYPE html>
<html class="no-js" lang="en-US" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#">
<head>
	<meta name="generator" content="Hugo 0.30.2" />
    <meta charset="utf-8">

    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="description" content="">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">


<meta name="keywords" content="">

 
<meta property="og:type" content="article"/>
<meta property="og:description" content=""/>
<meta property="og:title" content="import python : spf13.com"/>
<meta property="og:site_name" content="spf13 is Steve Francia"/>
<meta property="og:image" content="" />
<meta property="og:image:type" content="image/jpeg" />
<meta property="og:image:width" content="" />
<meta property="og:image:height" content="" />
<meta property="og:url" content="https://guanfuchen.github.io/">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2018-03-03"/>
<meta property="article:modified_time" content="2018-03-03"/>





<meta name="twitter:card" content="summary">

<meta name="twitter:site" content="@spf13">
<meta name="twitter:title" content="import python : spf13.com">
<meta name="twitter:creator" content="@spf13">
<meta name="twitter:description" content="">
<meta name="twitter:image:src" content="">
<meta name="twitter:domain" content="spf13.com">



    <base href="https://guanfuchen.github.io">
    <title>import python</title>
    <link rel="canonical" href="https://guanfuchen.github.io/">
    <link href="https://guanfuchen.github.io/index.xml" rel="alternate" type="application/rss+xml" title="import python" />

    <link href='https://fonts.lug.ustc.edu.cn/css?family=Fjalla+One|Open+Sans:300' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="https://guanfuchen.github.io/static/css/style.css">

</head>
<body lang="en">

<header id="header">
    
      
    
    <div align="center">
        <a href="https://guanfuchen.github.io">
        <img src="https://guanfuchen.github.io/media/avatar.png">
        </a>
    </div>
    <div align="center">guanfuchen</div>
    <nav id="nav">
            <ul id="mainnav">
            <li>
                <a href="https://guanfuchen.github.io/post/">
                <span class="icon"> <i aria-hidden="true" class="icon-quill"></i></span>
                <span> 博客 </span>
            </a>
            </li>
            
            
                
                
            
            
            
            
                
                
            
            
            <li>
            <a href="http://github.com/guanfuchen">
                <span class="icon"> <i aria-hidden="true" class="icon-13"></i></span>
                <span> 关于 </span>
            </a>
            </li>
            <li>
                <a href="https://guanfuchen.github.io/resume.pdf">
                    <span class="icon"> <i aria-hidden="true" class="icon-console"></i></span>
                    <span> 简历 </span>
                </a>
            </li>
        </ul>

    
    </nav>
</header>


<section id="main">
  <div>
      <h1 id="title">import python</h1>
    
        <article class="post">
    <header>
      <h2><a href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2018_03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">深度学习基础 </a> </h2>
      <div class="post-meta">Sat, Mar 3, 2018 -  Read in 1 Min </div>
    </header>

    阅读书籍 Data-Science-books 收集了部分关于深度学习的书籍
 《深度学习》，Bengio和Goodfellow DeepLearningBookQA_cn 那些深度学习《面试》你可能需要知道的 斯坦福机器学习课程 《统计学习方法》，李航 lihang_book_algorithm 作者使用python实现了所有的算法 li_hang 李航书籍的PPT static_study 《统计学习方法》的读书笔记 统计学习方法：习题笔记 习题的笔记 返回主页 刘建平Pinard 博主整理了很多书上的内容，可以作为复习参考 《神经网络与深度学习》，吴岸城 《神经网络与深度学习》讲义 《神经网络与深度学习》讲义（Notes on Artificial Neural Networks and Deep Learning）从感知器到多层感知器到卷积网络 《机器学习》，周志华 机器学习：习题笔记（一） 提供了课后习题的相关思路 《斯坦福大学2014机器学习课程笔记》，Andrew Ng主讲，黄海广整理笔记 《凸优化》为什么凸优化这么重要？ 機器學習中的優化理論，需要學習哪些資料才能看懂？ 凸优化书籍推荐？ 《Neural Networks and Learning Machines》 機器學習基石上 (Machine Learning Foundations)&mdash;Mathematical Foundations 机器学习资料大汇总 机器学习学习大纲 对于机器学习中常用的模型和数学知识进行了罗列，其中的知识介绍接近李航的统计学系方法，很有系统性，推荐。  相关博客 关于计算机视觉（随谈）
参数调整 你有哪些deep learning（rnn、cnn）调参的经验？ 这篇文章对神经网络中常用的参数调整进行了介绍，非常有帮助。
线性回归 推导过程
反向传播 四个基本公式
Backpropagation Algorithm
反向传播算法
Improving the way neural networks learn
    <footer>
        <a href='https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2018_03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/'><nobr>Read more →</nobr></a>
    </footer>
</article>

    
        <article class="post">
    <header>
      <h2><a href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2018_03/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%88%86%E4%BA%AB/">神经网络分享 </a> </h2>
      <div class="post-meta">Sat, Mar 3, 2018 -  Read in 3 Min </div>
    </header>

    神经网络（Neural Network） 第四期分享会 汇报人：陈官富 2018.3.23 引言 神经网络被广泛应用在图像分类、图像分割、目标跟踪等领域 引言 引言 引言 引言 人工智能、机器学习、表示学习、深度学习和CNN之间的关系 引言 传统机器学习 VS 深度学习
引言 典型的图像分类Pipeline
多层感知机-卷积神经网络**），感知器可以实现简单的分类操作，由**感知器**组成的一个**多层感知机**（MLP）能够表示更大的假设空间（学习能力更强），实现权值共享的多层感知机也就是卷积神经网络，减少了训练的参数，极大地加快了训练，增强了上下文信息建模能力，从而被广泛应用在图像、语音等二维数据上。 -- 目录  感知器（Perceptron）  梯度下降算法（Gradient Descent）  多层感知器（MLP）  反向传播算法（Back Propogation）  卷积神经网络（Convolution Neural Network） 循环神经网络（Recurrent Neural Network）  感知器 感知器 输入：样本的特征向量$x$ 输出：样本的类别$y \in {-1, +1}$ 模型： $$f(x)=sign(w \cdot x+b)$$ $$sign(x)=\begin{cases} 1&amp; if&amp; x&gt;0
0&amp; if&amp; x \leq 0 \end{cases}$$ 其中$w$和$b$是感知器参数，$w$是权重（weight），$b$是偏置（bias），$sign$是符号函数。
感知器 $$y_i=sign(w^{(1)}x_i^{(1)}+w^{(2)}x_i^{(2)}+&hellip;+w^{(d)}x_i^{(d)}+b)$$ 其中$i=1,2,&hellip;,N,$，$N$为样本数，$d$为输入样本的特征维度，训练集为$T={x_1,x_2,&hellip;,x_N}$，$y_i \in {-1, +1}$，$+1$表示正样本，$-1$表示负样本。 感知器 感知器 计算简单的逻辑功能
    <footer>
        <a href='https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2018_03/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%88%86%E4%BA%AB/'><nobr>Read more →</nobr></a>
    </footer>
</article>

    
        <article class="post">
    <header>
      <h2><a href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2018_02/leetcode%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/">LeetCode相关问题 </a> </h2>
      <div class="post-meta">Mon, Feb 26, 2018 -  Read in 1 Min </div>
    </header>

    鸡汤 LeetCode 刷题指南（一）：为什么要刷题 对leetcode的评价非常客观
常用算法 并查集(Union-Find)算法介绍
LeetCode 解题报告(684，685)-并查集介绍及应用
遗留问题 725. Split Linked List in Parts
654. Maximum Binary Tree 题目大意： 给定无重复的数组。一棵最大树定义如下： 从数组中挑选最大的数字作为根 挑选左半数组中最大的数字作为左子树的根 挑选右半数组中最大的数字作为右子树的根 递归此过程。
# Definition for a binary tree node. # class TreeNode(object): # def __init__(self, x): # self.val = x # self.left = None # self.right = None class Solution(object): def constructMaximumBinaryTree(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: TreeNode &quot;&quot;&quot; if not nums: return None maxn = max(nums) idx = nums.
    <footer>
        <a href='https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2018_02/leetcode%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/'><nobr>Read more →</nobr></a>
    </footer>
</article>

    
        <article class="post">
    <header>
      <h2><a href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2018_02/kmp%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/">KMP算法相关 </a> </h2>
      <div class="post-meta">Mon, Feb 26, 2018 -  Read in 2 Min </div>
    </header>

    相关资料 可参考大话数据结构中串的一节KMP匹配 Algorithm Implementation/String searching/Knuth-Morris-Pratt pattern matcher 字符串匹配的KMP算法 主要参考大神阮一峰进行学习的，下面均来自于其博客。 The Knuth-Morris-Pratt Algorithm in my own words
核心思路是将比较过的位置不要继续进行比较，其中使用《部分匹配表》（Partial Match Table）既可以解决这个问题。已知空格与D不匹配时，前面六个字符&rdquo;ABCDAB&rdquo;是匹配的。查表可知，最后一个匹配字符B对应的&rdquo;部分匹配值&rdquo;为2，因此按照下面的公式算出向后移动的位数：
移动位数 = 已匹配的字符数 - 对应的部分匹配值 因为 6 - 2 等于4，所以将搜索词向后移动4位。  下面介绍《部分匹配表》是如何产生的。
首先，要了解两个概念：&rdquo;前缀&rdquo;和&rdquo;后缀&rdquo;。 &ldquo;前缀&rdquo;指除了最后一个字符以外，一个字符串的全部头部组合；&rdquo;后缀&rdquo;指除了第一个字符以外，一个字符串的全部尾部组合。
&ldquo;部分匹配值&rdquo;就是&rdquo;前缀&rdquo;和&rdquo;后缀&rdquo;的最长的共有元素的长度。以&rdquo;ABCDABD&rdquo;为例，
　－　&quot;A&quot;的前缀和后缀都为空集，共有元素的长度为0； －　&quot;AB&quot;的前缀为[A]，后缀为[B]，共有元素的长度为0； －　&quot;ABC&quot;的前缀为[A, AB]，后缀为[BC, C]，共有元素的长度0； －　&quot;ABCD&quot;的前缀为[A, AB, ABC]，后缀为[BCD, CD, D]，共有元素的长度为0； －　&quot;ABCDA&quot;的前缀为[A, AB, ABC, ABCD]，后缀为[BCDA, CDA, DA, A]，共有元素为&quot;A&quot;，长度为1； －　&quot;ABCDAB&quot;的前缀为[A, AB, ABC, ABCD, ABCDA]，后缀为[BCDAB, CDAB, DAB, AB, B]，共有元素为&quot;AB&quot;，长度为2； －　&quot;ABCDABD&quot;的前缀为[A, AB, ABC, ABCD, ABCDA, ABCDAB]，后缀为[BCDABD, CDABD, DABD, ABD, BD, D]，共有元素的长度为0。  &ldquo;部分匹配&rdquo;的实质是，有时候，字符串头部和尾部会有重复。比如，&rdquo;ABCDAB&rdquo;之中有两个&rdquo;AB&rdquo;，那么它的&rdquo;部分匹配值&rdquo;就是2（&rdquo;AB&rdquo;的长度）。搜索词移动的时候，第一个&rdquo;AB&rdquo;向后移动4位（字符串长度-部分匹配值），就可以来到第二个&rdquo;AB&rdquo;的位置。
    <footer>
        <a href='https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2018_02/kmp%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/'><nobr>Read more →</nobr></a>
    </footer>
</article>

    
        <article class="post">
    <header>
      <h2><a href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2018_01/hpec%E6%9C%88%E4%BE%8B%E4%BC%9A_2018%E5%B9%B4_1%E6%9C%88/">HPEC月例会_2018年_1月 </a> </h2>
      <div class="post-meta">Tue, Jan 2, 2018 -  Read in 1 Min </div>
    </header>

    图像拼接 维护标签图和原始图，不断增加贴图扩大语义地图 图像拼接算法简述如下：
 提取特征点并计算描述子，如SIFT、SURF、ORB等 匹配特征点，计算H矩阵，两幅图像的变换矩阵 使用H矩阵将新图warp到一个柱面上，和旧图进行拼接 拼接后的图片作为旧图，新图循环上述操作形成大图  语义地图拼接算法简述如下：
 提取特征点并计算描述子，如SIFT、SURF、ORB等 匹配特征点，计算H矩阵，两幅图像的变换矩阵 输入语义网络中计算每一时刻当前的语义标签 使用H矩阵将新图warp到一个柱面上，和旧图进行拼接使用H矩阵将新语义标签图warp到一个柱面上，和旧语义标签图进行拼接 拼接后的图片作为旧图，新图循环上述操作形成大图  测试图像gif 最后拼接的大图 工大无人机视频语义图拼接原图 工大无人机视频语义图拼接结果 具体代码仓库和结构如下： def main(): # Get input set of images img1 = cv2.imread(sys.argv[1]) img2 = cv2.imread(sys.argv[2]) img1_label = None img2_label = None if len(sys.argv) == 5: img1_label = cv2.imread(sys.argv[3]) img2_label = cv2.imread(sys.argv[4]) # print('img1_label:', img1_label) # print('img2_label:', img2_label) # Equalize histogram img1 = equalize_histogram_color(img1) img2 = equalize_histogram_color(img2) # Show input images #input_images = np.
    <footer>
        <a href='https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2018_01/hpec%E6%9C%88%E4%BE%8B%E4%BC%9A_2018%E5%B9%B4_1%E6%9C%88/'><nobr>Read more →</nobr></a>
    </footer>
</article>

    
        <article class="post">
    <header>
      <h2><a href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_12/%E5%BE%AE%E4%BF%A1%E5%BC%80%E5%8F%91%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/">微信开发相关内容 </a> </h2>
      <div class="post-meta">Wed, Dec 27, 2017 -  Read in 1 Min </div>
    </header>

    调用接口查看 接口调用频次限制说明
接口权限
WeRoBot.Client —— 微信 API 操作类
    <footer>
        <a href='https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_12/%E5%BE%AE%E4%BF%A1%E5%BC%80%E5%8F%91%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/'><nobr>Read more →</nobr></a>
    </footer>
</article>

    
        <article class="post">
    <header>
      <h2><a href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_12/nips%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/">NIPS资料整理 </a> </h2>
      <div class="post-meta">Fri, Dec 15, 2017 -  Read in 1 Min </div>
    </header>

    NIPS2017 收集NIPS 2017相关文章
nips_2017
    <footer>
        <a href='https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_12/nips%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/'><nobr>Read more →</nobr></a>
    </footer>
</article>

    
        <article class="post">
    <header>
      <h2><a href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_12/efficient_convnet_for_real-time_semantic_segmentation%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">Efficient_ConvNet_for_Real Time_Semantic_Segmentation论文阅读 </a> </h2>
      <div class="post-meta">Fri, Dec 15, 2017 -  Read in 1 Min </div>
    </header>

    论文资料 ERFNet: Efficient Residual Factorized ConvNet for Real-time Semantic Segmentation
Efficient ConvNet for Real-time Semantic Segmentation
代码运行 erfnet
erfnet_pytorch
相关描述 这些文章关注点在语义分割实时性上。
    <footer>
        <a href='https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_12/efficient_convnet_for_real-time_semantic_segmentation%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/'><nobr>Read more →</nobr></a>
    </footer>
</article>

    
        <article class="post">
    <header>
      <h2><a href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_12/one-shot_video_object_segmentation%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">One Shot_Video_Object_Segmentation论文阅读 </a> </h2>
      <div class="post-meta">Thu, Dec 14, 2017 -  Read in 1 Min </div>
    </header>

    论文资料 One-Shot Video Object Segmentation(OSVOS) 论文 OSVOS-caffe OSVOS-TensorFlow 项目主页
博客资料 One-Shot Video Object Segmentation论文笔记
相关描述 本文任务为从视频中的第一帧mask分割将来帧的物体。
    <footer>
        <a href='https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_12/one-shot_video_object_segmentation%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/'><nobr>Read more →</nobr></a>
    </footer>
</article>

    
        <article class="post">
    <header>
      <h2><a href="https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_12/%E7%BD%91%E7%BB%9Closs%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99/">网络loss相关资料 </a> </h2>
      <div class="post-meta">Tue, Dec 12, 2017 -  Read in 1 Min </div>
    </header>

    博客资料 pytorch loss function 总结
PyTorch中的Loss Fucntion
相关描述 分类模型使用cross-entropy而不是classifier error的原因是，分类模型用cross-entropy。这里使用一个例子来解释cross-entropy在分类模型中的优势。
深度学习中的Loss Function有很多，常见的有L1、L2、HingeLoss、CrossEntropy，其最终目的就是计算预测的 f(x)f(x) 与真值 yy 之间的差别，而优化器的目的就是minimize这个差值，当loss的值稳定后，便是f(x)f(x) 的参数WW最优的时候。
首先引入交叉熵的概念。Cross Entropy（也就是交叉熵）来自香农的信息论，简单来说，交叉熵是用来衡量在给定的真实分布pkpk下，使用非真实分布qkqk所指定的策略 f(x)f(x) 消除系统的不确定性所需要付出的努力的大小。交叉熵的越低说明这个策略越好，我们总是minimize交叉熵，因为交叉熵越小，就证明算法所产生的策略越接近最优策略，也就间接证明我们的算法所计算出的非真实分布越接近真实分布。交叉熵损失函数从信息论的角度来说，其实来自于KL散度，只不过最后推导的新式等价于交叉熵的计算公式：
$$H(p,q)=-\sum_{k=1}^{N}(p_k*\log{q_k})$$
最大似然估计、Negative Log Liklihood(NLL)、KL散度与Cross Entropy其实是等价的，都可以进行互相推导，当然MSE也可以用Cross Entropy进行对到出（详见Deep Learning Book P132）。
分类模型的 Loss 为什么使用 cross entropy 而不是 classification error 或 squared error
    <footer>
        <a href='https://guanfuchen.github.io/post/markdown_blog_ws/markdown_blog_2017_12/%E7%BD%91%E7%BB%9Closs%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99/'><nobr>Read more →</nobr></a>
    </footer>
</article>

    
  </div>
</section>

<aside id="meta"> </aside>

<footer>
  <div>
    <p>
    &copy; 2017 <span itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">guanfuchen.</span></span>
    Powered by <a href="http://gohugo.io">Hugo</a>.
  </div>
</footer>
<script type="text/javascript">
(function(){var j=function(a,b){return window.getComputedStyle?getComputedStyle(a).getPropertyValue(b):a.currentStyle[b]};var k=function(a,b,c){if(a.addEventListener)a.addEventListener(b,c,false);else a.attachEvent('on'+b,c)};var l=function(a,b){for(key in b)if(b.hasOwnProperty(key))a[key]=b[key];return a};window.fitText=function(d,e,f){var g=l({'minFontSize':-1/0,'maxFontSize':1/0},f);var h=function(a){var b=e||1;var c=function(){a.style.fontSize=Math.max(Math.min(a.clientWidth/(b*10),parseFloat(g.maxFontSize)),parseFloat(g.minFontSize))+'px'};c();k(window,'resize',c)};if(d.length)for(var i=0;i<d.length;i++)h(d[i]);else h(d);return d}})();
fitText(document.getElementById('title'), 1)
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-7131036-1', 'spf13.com');
  ga('require', 'linkid', 'linkid.js');
  ga('require', 'displayfeatures');
  ga('send', 'pageview');
</script>
</body>
</html>

